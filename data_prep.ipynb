{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "Este notebook é dedicado ao data prep e exportação de um csv com os dados trabalhados ('diabetic_data_df.csv') e as colunas utilizadas ('col2use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file\n",
    "df = pd.read_csv('diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algumas análises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 101766\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows for each type\n",
    "df.groupby('readmitted').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discharge_disposition_id, tells us where the patient went after the hospitalization.\n",
    "df.groupby('discharge_disposition_id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualização de 10 em 10 colunas\n",
    "df[list(df.columns)[:10]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualização de 10 em 10 colunas\n",
    "df[list(df.columns)[10:20]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualização de 10 em 10 colunas\n",
    "df[list(df.columns)[20:30]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualização de 10 em 10 colunas\n",
    "df[list(df.columns)[30:40]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualização de 10 em 10 colunas\n",
    "df[list(df.columns)[40:]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra os IDs unicos da base se forem (em quantidade) menores que 30, caso contrário diz quantos são\n",
    "# for each column\n",
    "for c in list(df.columns):\n",
    "    \n",
    "    # get a list of unique values\n",
    "    n = df[c].unique()\n",
    "    \n",
    "    # if number of unique values is less than 30, print the values. Otherwise print the number of unique values\n",
    "    if len(n)<30:\n",
    "        print(c)\n",
    "        print(n)\n",
    "    else:\n",
    "        print(c + ': ' +str(len(n)) + ' unique values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De acordo com IDs_mapping.csv os IDs 11,13,14,19,20,21 são relacionados a morte ou hospício. Remover esses IDs do modelo.\n",
    "df = df.loc[~df.discharge_disposition_id.isin([11,13,14,19,20,21])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a coluna de output para classificação binária\n",
    "df['OUTPUT_LABEL'] = (df.readmitted == '<30').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ? with nan\n",
    "df = df.replace('?',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nas colunas 'race', 'player_code' e 'medical_specialty' estao faltando dados, preencher com 'UNK'\n",
    "df['race'] = df['race'].fillna('UNK')\n",
    "df['payer_code'] = df['payer_code'].fillna('UNK')\n",
    "df['medical_specialty'] = df['medical_specialty'].fillna('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobre a coluna 'medical_specialty', pega os top 10 mais recorrentes e cria uma nova coluna contendo somente estes top 10\n",
    "# os outros dados que não estão dentro dos top 10 são classificados como 'Other'\n",
    "top_10 = ['UNK','InternalMedicine','Emergency/Trauma',\\\n",
    "          'Family/GeneralPractice', 'Cardiology','Surgery-General' ,\\\n",
    "          'Nephrology','Orthopedics',\\\n",
    "          'Orthopedics-Reconstructive','Radiologist']\n",
    "\n",
    "# make a new column with duplicated data\n",
    "df['med_spec'] = df['medical_specialty'].copy()\n",
    "\n",
    "# replace all specialties not in top 10 with 'Other' category\n",
    "df.loc[~df.med_spec.isin(top_10),'med_spec'] = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our categorical features to numbers, we will use a technique called one-hot encoding. In one-hot encoding, you create a new column for each unique value in that column. Then the value of the column is 1 if the sample has that unique value or 0 otherwise. For example, for the column race, we would create new columns ('race_Caucasian','race_AfricanAmerican', etc). If the patient's race is Caucasian, the patient gets a 1 under 'race_Caucasian' and 0 under the rest of the race columns. To create these one-hot encoding columns, we can use the get_dummies function.\n",
    "\n",
    "Now the problem is that if we create a column for each unique value, we have correlated columns. In other words, the value in one column can be figured out by looking at the rest of the columns. For example, if the sample is not AfricanAmerican, Asian, Causasian, Hispance or Other, it must be UNK. To deal with this, we can use the drop_first option, which will drop the first categorical value for each column.\n",
    "\n",
    "The get_dummies function does not work on numerical data. To trick get_dummies, we can convert the numerical data into strings and then it will work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race_Asian', 'race_Caucasian', 'race_Hispanic', 'race_Other', 'race_UNK', 'gender_Male', 'gender_Unknown/Invalid', 'max_glu_serum_>300', 'max_glu_serum_None', 'max_glu_serum_Norm', 'A1Cresult_>8', 'A1Cresult_None', 'A1Cresult_Norm', 'metformin_No', 'metformin_Steady', 'metformin_Up', 'repaglinide_No', 'repaglinide_Steady', 'repaglinide_Up', 'nateglinide_No', 'nateglinide_Steady', 'nateglinide_Up', 'chlorpropamide_No', 'chlorpropamide_Steady', 'chlorpropamide_Up', 'glimepiride_No', 'glimepiride_Steady', 'glimepiride_Up', 'acetohexamide_Steady', 'glipizide_No', 'glipizide_Steady', 'glipizide_Up', 'glyburide_No', 'glyburide_Steady', 'glyburide_Up', 'tolbutamide_Steady', 'pioglitazone_No', 'pioglitazone_Steady', 'pioglitazone_Up', 'rosiglitazone_No', 'rosiglitazone_Steady', 'rosiglitazone_Up', 'acarbose_No', 'acarbose_Steady', 'acarbose_Up', 'miglitol_No', 'miglitol_Steady', 'miglitol_Up', 'troglitazone_Steady', 'tolazamide_Steady', 'tolazamide_Up', 'insulin_No', 'insulin_Steady', 'insulin_Up', 'glyburide-metformin_No', 'glyburide-metformin_Steady', 'glyburide-metformin_Up', 'glipizide-metformin_Steady', 'glimepiride-pioglitazone_Steady', 'metformin-rosiglitazone_Steady', 'metformin-pioglitazone_Steady', 'change_No', 'diabetesMed_Yes', 'payer_code_CH', 'payer_code_CM', 'payer_code_CP', 'payer_code_DM', 'payer_code_FR', 'payer_code_HM', 'payer_code_MC', 'payer_code_MD', 'payer_code_MP', 'payer_code_OG', 'payer_code_OT', 'payer_code_PO', 'payer_code_SI', 'payer_code_SP', 'payer_code_UN', 'payer_code_UNK', 'payer_code_WC', 'admission_type_id_2', 'admission_type_id_3', 'admission_type_id_4', 'admission_type_id_5', 'admission_type_id_6', 'admission_type_id_7', 'admission_type_id_8', 'discharge_disposition_id_10', 'discharge_disposition_id_12', 'discharge_disposition_id_15', 'discharge_disposition_id_16', 'discharge_disposition_id_17', 'discharge_disposition_id_18', 'discharge_disposition_id_2', 'discharge_disposition_id_22', 'discharge_disposition_id_23', 'discharge_disposition_id_24', 'discharge_disposition_id_25', 'discharge_disposition_id_27', 'discharge_disposition_id_28', 'discharge_disposition_id_3', 'discharge_disposition_id_4', 'discharge_disposition_id_5', 'discharge_disposition_id_6', 'discharge_disposition_id_7', 'discharge_disposition_id_8', 'discharge_disposition_id_9', 'admission_source_id_10', 'admission_source_id_11', 'admission_source_id_13', 'admission_source_id_14', 'admission_source_id_17', 'admission_source_id_2', 'admission_source_id_20', 'admission_source_id_22', 'admission_source_id_25', 'admission_source_id_3', 'admission_source_id_4', 'admission_source_id_5', 'admission_source_id_6', 'admission_source_id_7', 'admission_source_id_8', 'admission_source_id_9', 'med_spec_Emergency/Trauma', 'med_spec_Family/GeneralPractice', 'med_spec_InternalMedicine', 'med_spec_Nephrology', 'med_spec_Orthopedics', 'med_spec_Orthopedics-Reconstructive', 'med_spec_Other', 'med_spec_Radiologist', 'med_spec_Surgery-General', 'med_spec_UNK']\n"
     ]
    }
   ],
   "source": [
    "cols_cat = ['race', 'gender', \n",
    "       'max_glu_serum', 'A1Cresult',\n",
    "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "       'tolazamide', 'insulin',\n",
    "       'glyburide-metformin', 'glipizide-metformin',\n",
    "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "       'metformin-pioglitazone', 'change', 'diabetesMed','payer_code']\n",
    "\n",
    "cols_cat_num = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "\n",
    "df[cols_cat_num] = df[cols_cat_num].astype('str')\n",
    "\n",
    "df_cat = pd.get_dummies(df[cols_cat + cols_cat_num + ['med_spec']],drop_first = True)\n",
    "\n",
    "df = pd.concat([df,df_cat], axis = 1)\n",
    "\n",
    "# salva as colunas de dados categóricos em 'cols_all_cat'\n",
    "cols_all_cat = list(df_cat.columns)\n",
    "print (df_cat.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformação das colunas de idade e peso de categóricas para numéricas\n",
    "age_id = {'[0-10)':0, \n",
    "          '[10-20)':10, \n",
    "          '[20-30)':20, \n",
    "          '[30-40)':30, \n",
    "          '[40-50)':40, \n",
    "          '[50-60)':50,\n",
    "          '[60-70)':60, \n",
    "          '[70-80)':70, \n",
    "          '[80-90)':80, \n",
    "          '[90-100)':90}\n",
    "df['age_group'] = df.age.replace(age_id)\n",
    "\n",
    "df['has_weight'] = df.weight.notnull().astype('int')\n",
    "\n",
    "# salva as colunas 'age_group' e 'has_weight'\n",
    "cols_extra = ['age_group','has_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_num = ['time_in_hospital','num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "       'number_outpatient', 'number_emergency', 'number_inpatient','number_diagnoses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o df_data que é o dataframe final com os dados utilizados\n",
    "col2use = cols_num + cols_all_cat + cols_extra\n",
    "col2use_df = pd.DataFrame(list(col2use), columns=['col2use'])\n",
    "col2use_df.to_csv('col2use.csv')\n",
    "\n",
    "df_data = df[col2use + ['OUTPUT_LABEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporta csv do dataframe final\n",
    "df_data.to_csv(path_or_buf=\"diabetic_data_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
