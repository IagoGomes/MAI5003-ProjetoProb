{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the final dataframe from data_prep \n",
    "df_fulldata = pd.read_csv('diabetic_data_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load columns to use from data_prep\n",
    "col2use = pd.read_csv('col2use.csv')\n",
    "col2use = col2use['col2use'].tolist()\n",
    "    \n",
    "df_data = df_fulldata[col2use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>...</th>\n",
       "      <th>med_spec_InternalMedicine</th>\n",
       "      <th>med_spec_Nephrology</th>\n",
       "      <th>med_spec_Orthopedics</th>\n",
       "      <th>med_spec_Orthopedics-Reconstructive</th>\n",
       "      <th>med_spec_Other</th>\n",
       "      <th>med_spec_Radiologist</th>\n",
       "      <th>med_spec_Surgery-General</th>\n",
       "      <th>med_spec_UNK</th>\n",
       "      <th>age_group</th>\n",
       "      <th>has_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0                 1                  41               0                1   \n",
       "1                 3                  59               0               18   \n",
       "2                 2                  11               5               13   \n",
       "3                 2                  44               1               16   \n",
       "4                 1                  51               0                8   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0                  0                 0                 0                 1   \n",
       "1                  0                 0                 0                 9   \n",
       "2                  2                 0                 1                 6   \n",
       "3                  0                 0                 0                 7   \n",
       "4                  0                 0                 0                 5   \n",
       "\n",
       "   race_Asian  race_Caucasian  ...  med_spec_InternalMedicine  \\\n",
       "0           0               1  ...                          0   \n",
       "1           0               1  ...                          0   \n",
       "2           0               0  ...                          0   \n",
       "3           0               1  ...                          0   \n",
       "4           0               1  ...                          0   \n",
       "\n",
       "   med_spec_Nephrology  med_spec_Orthopedics  \\\n",
       "0                    0                     0   \n",
       "1                    0                     0   \n",
       "2                    0                     0   \n",
       "3                    0                     0   \n",
       "4                    0                     0   \n",
       "\n",
       "   med_spec_Orthopedics-Reconstructive  med_spec_Other  med_spec_Radiologist  \\\n",
       "0                                    0               1                     0   \n",
       "1                                    0               0                     0   \n",
       "2                                    0               0                     0   \n",
       "3                                    0               0                     0   \n",
       "4                                    0               0                     0   \n",
       "\n",
       "   med_spec_Surgery-General  med_spec_UNK  age_group  has_weight  \n",
       "0                         0             0          0           0  \n",
       "1                         0             1         10           0  \n",
       "2                         0             1         20           0  \n",
       "3                         0             1         30           0  \n",
       "4                         0             1         40           0  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the samples\n",
    "df_data = df_data.sample(n = len(df_data), random_state = 42)\n",
    "df_data = df_data.reset_index(drop = True)\n",
    "\n",
    "#print ('OUTPUT_LABEL' in df_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Size classes:\n",
      "\tno   [0] => 88029.0 => 0.886\n",
      "\tyes  [1] => 11314.0 => 0.114\n",
      "==> Size stratified\n",
      "\tno   [0] => 11314.0 => 0.5\n",
      "\tyes  [1] => 11314.0 => 0.5\n",
      "==> Dataset split:\n",
      "\ttrain => input=(18102, 143) | output=(18102,)\n",
      "\ttest  => input=(4526, 143)  | output=(4526,)\n"
     ]
    }
   ],
   "source": [
    "#split dataset \n",
    "# -> stratified split\n",
    "# -> 80% train\n",
    "#    -> k-fold (k=4)\n",
    "# -> 20% test\n",
    "#    -> confusion matrix\n",
    "#    -> accuracy\n",
    "#    -> sensitivity\n",
    "#    -> recall\n",
    "\n",
    "#X = df_data.values #input\n",
    "#Y = df_fulldata['OUTPUT_LABEL'].values\n",
    "\n",
    "Y_o_no  = np.where(df_fulldata['OUTPUT_LABEL'].values == 0)[0]\n",
    "Y_o_yes = np.where(df_fulldata['OUTPUT_LABEL'].values == 1)[0]\n",
    "\n",
    "class_names = {1:'yes', 0:'no'}\n",
    "names = ['no', 'yes']\n",
    "\n",
    "#original base\n",
    "print ('==> Size classes:')\n",
    "for c in np.unique(df_fulldata['OUTPUT_LABEL'].values):\n",
    "    s = np.sum(df_fulldata['OUTPUT_LABEL'].values == c).astype(np.float)\n",
    "    print ('\\t{:4} [{:1}] => {:5} => {:3}'.format(class_names[c], c,\\\n",
    "                                                  s, round(s/len(df_fulldata['OUTPUT_LABEL'].values), 3)))\n",
    "    \n",
    "#stratified base\n",
    "print ('==> Size stratified') #~50% yes 50%no\n",
    "i_y_no = np.random.choice(range(0, len(Y_o_no)), len(Y_o_yes))\n",
    "X = np.concatenate((df_data.values[Y_o_yes], df_data.values[Y_o_no[i_y_no]]), axis=0)\n",
    "Y = np.concatenate((df_fulldata['OUTPUT_LABEL'].values[Y_o_yes], \\\n",
    "                    df_fulldata['OUTPUT_LABEL'].values[Y_o_no[i_y_no]]), axis=0)\n",
    "\n",
    "for c in np.unique(Y):\n",
    "    s = np.sum(Y == c).astype(np.float)\n",
    "    print ('\\t{:4} [{:1}] => {:5} => {:3}'.format(class_names[c], c, s, round(s/len(Y), 3)))\n",
    "\n",
    "#split dataset: train and test\n",
    "X_train, X_test, Y_train,  Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y) \n",
    "\n",
    "#normalized data\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print ('==> Dataset split:')\n",
    "print ('\\ttrain => input={} | output={}'.format(X_train.shape, Y_train.shape))\n",
    "print ('\\ttest  => input={}  | output={}'.format(X_test.shape, Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, \\\n",
    "                            average_precision_score, f1_score, precision_score,\\\n",
    "                            recall_score, roc_auc_score, log_loss, confusion_matrix\n",
    "\n",
    "def report(y_true, y_pred, prefix):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    ap      = average_precision_score(y_true, y_pred)\n",
    "    f1      = f1_score(y_true, y_pred)\n",
    "    lloss   = log_loss(y_true, y_pred)\n",
    "    prec    = precision_score(y_true, y_pred)\n",
    "    recall  = recall_score(y_true, y_pred)\n",
    "    auc     = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print ('{} Accuracy :{:3}'.format(prefix, accuracy))\n",
    "    print ('{} AP:       {:3}'.format(prefix, ap))\n",
    "    print ('{} F1-score :{:3}'.format(prefix, f1))\n",
    "    print ('{} Log-Loss :{:3}'.format(prefix, lloss))\n",
    "    print ('{} Precision:{:3}'.format(prefix, prec))\n",
    "    print ('{} Recall   :{:3}'.format(prefix, recall))\n",
    "    print ('{} AUC      :{:3}'.format(prefix, auc))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def make_confusion_matrix(y_true, y_pred, names, normalized, prefix='', path=''):\n",
    "    \n",
    "    title = 'Confusion Matrix'\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "     \n",
    "    if normalized:\n",
    "        cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=names, \n",
    "           yticklabels=names,\n",
    "           ylabel='True Label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right',\n",
    "                                   rotation_mode='anchor')\n",
    "    \n",
    "    fmt = '.2f' if normalized else 'd'\n",
    "    thresh = cm.max()/2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha='center', va='center',\n",
    "                    color='green')#'white' if cm[i,j] > thresh else 'black')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if path != '':\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# penalty     = l2\n",
    "# loss        = hinge\n",
    "# dual        = False\n",
    "# tol         = 1e-6\n",
    "# C           = 1.0\n",
    "# multi_class = ovr\n",
    "# verbose     = 0\n",
    "# random_state= 42\n",
    "# max_iter    = 1e6\n",
    "_linear_svm = LinearSVC(dual=False, tol=1e-7, random_state=42, max_iter=1e7)\n",
    "linear_svm  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training Linear SVM:\n",
      "\t\u001b[94m iteration 0\u001b[0m\n",
      "\t\t train size: input= (13576, 143) | output= (13576,)\n",
      "\t\t valid size: input= (4526, 143) | output= (4526,)\n",
      "\t\t report train:\n",
      "\t\t\t Accuracy :0.5349145550972304\n",
      "\t\t\t AP:       0.5187271900038091\n",
      "\t\t\t F1-score :0.5254058929645219\n",
      "\t\t\t Log-Loss :16.063660116477802\n",
      "\t\t\t Precision:0.5363720073664825\n",
      "\t\t\t Recall   :0.5148791985857395\n",
      "\t\t\t AUC      :0.5349145550972304\n",
      "\t\t report valid:\n",
      "\t\t\t Accuracy :0.5053026955368979\n",
      "\t\t\t AP:       0.5026809993744334\n",
      "\t\t\t F1-score :0.4921750963937401\n",
      "\t\t\t Log-Loss :17.086427026309863\n",
      "\t\t\t Precision:0.505591798695247\n",
      "\t\t\t Recall   :0.4794520547945205\n",
      "\t\t\t AUC      :0.5053026955368979\n",
      "\t\u001b[94m iteration 1\u001b[0m\n",
      "\t\t train size: input= (13576, 143) | output= (13576,)\n",
      "\t\t valid size: input= (4526, 143) | output= (4526,)\n",
      "\t\t report train:\n",
      "\t\t\t Accuracy :0.5321154979375369\n",
      "\t\t\t AP:       0.5171256529575394\n",
      "\t\t\t F1-score :0.5239808153477218\n",
      "\t\t\t Log-Loss :16.16033842284981\n",
      "\t\t\t Precision:0.5332519829164124\n",
      "\t\t\t Recall   :0.5150265173836182\n",
      "\t\t\t AUC      :0.5321154979375368\n",
      "\t\t report valid:\n",
      "\t\t\t Accuracy :0.49646486964206804\n",
      "\t\t\t AP:       0.49824523167300844\n",
      "\t\t\t F1-score :0.490498546836575\n",
      "\t\t\t Log-Loss :17.39168390542228\n",
      "\t\t\t Precision:0.49638009049773757\n",
      "\t\t\t Recall   :0.48475475033141846\n",
      "\t\t\t AUC      :0.49646486964206804\n",
      "\t\u001b[94m iteration 2\u001b[0m\n",
      "\t\t train size: input= (13576, 143) | output= (13576,)\n",
      "\t\t valid size: input= (4526, 143) | output= (4526,)\n",
      "\t\t report train:\n",
      "\t\t\t Accuracy :0.5300530347672363\n",
      "\t\t\t AP:       0.5159137560366596\n",
      "\t\t\t F1-score :0.5342385749744488\n",
      "\t\t\t Log-Loss :16.231584626603986\n",
      "\t\t\t Precision:0.5295224312590449\n",
      "\t\t\t Recall   :0.5390394814378314\n",
      "\t\t\t AUC      :0.5300530347672363\n",
      "\t\t report valid:\n",
      "\t\t\t Accuracy :0.5108263367211666\n",
      "\t\t\t AP:       0.5055291479188118\n",
      "\t\t\t F1-score :0.5134065934065934\n",
      "\t\t\t Log-Loss :16.895657465279857\n",
      "\t\t\t Precision:0.5107127240926979\n",
      "\t\t\t Recall   :0.5161290322580645\n",
      "\t\t\t AUC      :0.5108263367211666\n",
      "\t\u001b[94m iteration 3\u001b[0m\n",
      "\t\t train size: input= (13578, 143) | output= (13578,)\n",
      "\t\t valid size: input= (4524, 143) | output= (4524,)\n",
      "\t\t report train:\n",
      "\t\t\t Accuracy :0.5380026513477685\n",
      "\t\t\t AP:       0.5205685705664234\n",
      "\t\t\t F1-score :0.5191261019547719\n",
      "\t\t\t Log-Loss :15.956992132118085\n",
      "\t\t\t Precision:0.5412404092071611\n",
      "\t\t\t Recall   :0.4987479746648991\n",
      "\t\t\t AUC      :0.5380026513477684\n",
      "\t\t report valid:\n",
      "\t\t\t Accuracy :0.5064102564102564\n",
      "\t\t\t AP:       0.503249537530474\n",
      "\t\t\t F1-score :0.487256027554535\n",
      "\t\t\t Log-Loss :17.04816818620325\n",
      "\t\t\t Precision:0.5069278547539418\n",
      "\t\t\t Recall   :0.46905393457117595\n",
      "\t\t\t AUC      :0.5064102564102564\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, random_state=42, shuffle=True)\n",
    "\n",
    "print ('==> training Linear SVM:')\n",
    "iteration = 0\n",
    "best_acc  = 0\n",
    "for itrain, ivalid in kfold.split(X_train, Y_train):\n",
    "    print ('\\t\\033[94m iteration {}\\033[0m'.format(iteration))\n",
    "    \n",
    "    #split dataset into train and valid, based on folds\n",
    "    xi_train, xi_valid = X_train[itrain], X_train[ivalid]\n",
    "    yi_train, yi_valid = Y_train[itrain], Y_train[ivalid]\n",
    "    print ('\\t\\t train size: input= {} | output= {}'.format(xi_train.shape, yi_train.shape))\n",
    "    print ('\\t\\t valid size: input= {} | output= {}'.format(xi_valid.shape, yi_valid.shape))\n",
    "        \n",
    "    #train\n",
    "    _linear_svm.fit(xi_train, yi_train)\n",
    "    \n",
    "    #valid\n",
    "    y_train_predicted = _linear_svm.predict(xi_train) \n",
    "    y_valid_predicted = _linear_svm.predict(xi_valid)\n",
    "    \n",
    "    #report\n",
    "    print ('\\t\\t report train:')\n",
    "    report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    print ('\\t\\t report valid:')\n",
    "    acc = report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    report_file = 'models/svm/linear/report_svm_{}.txt'.format(iteration)\n",
    "    if os.path.exists(report_file):\n",
    "        os.remove(report_file)\n",
    "    with open(report_file, 'w') as f:\n",
    "         with redirect_stdout(f):\n",
    "                print ('\\t\\t report train:')\n",
    "                report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "                print ('\\t\\t report valid:')\n",
    "                report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "                \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        linear_svm = _linear_svm\n",
    "        \n",
    "        with open('models/svm/linear/best_svm_model.txt', 'w') as f:\n",
    "            f.write(str(iteration))\n",
    "    \n",
    "    with open('models/svm/linear/svm_{}'.format(iteration), 'wb') as f:\n",
    "        f.write(pickle.dumps(_linear_svm))\n",
    "          \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = linear_svm.predict(X_test)\n",
    "\n",
    "print ('==> test Linear SVM')\n",
    "print ('\\t\\033[94m Report \\033[0m')\n",
    "_ = report(Y_test, y_test_predicted, prefix='\\t')\n",
    "print ('\\n')\n",
    "print ('\\t\\033[94m Normalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=True)\n",
    "print ('\\t\\033[94m Unnormalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "# nu     = 0.5\n",
    "# kernel = sigmoid\n",
    "# gamma  = 1/(n_features*X.var())\n",
    "# coef0  = 0\n",
    "# probability = True\n",
    "# tol    = 1e-7\n",
    "# verbose     = 0\n",
    "# random_state= 42\n",
    "# max_iter    = 1e7\n",
    "# decision_function_shape = 'ovr'\n",
    "_sigmoid_svm = NuSVC(kernel='sigmoid', gamma='scale', probability=True, tol=1e-7, max_iter=1e7, random_state=42)\n",
    "sigmoid_svm  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, random_state=42, shuffle=True)\n",
    "\n",
    "print ('==> training Sigmoid SVM:')\n",
    "iteration = 0\n",
    "best_acc  = 0\n",
    "for itrain, ivalid in kfold.split(X_train, Y_train):\n",
    "    print ('\\t\\033[94m iteration {}\\033[0m'.format(iteration))\n",
    "    \n",
    "    #split dataset into train and valid, based on folds\n",
    "    xi_train, xi_valid = X_train[itrain], X_train[ivalid]\n",
    "    yi_train, yi_valid = Y_train[itrain], Y_train[ivalid]\n",
    "    print ('\\t\\t train size: input= {} | output= {}'.format(xi_train.shape, yi_train.shape))\n",
    "    print ('\\t\\t valid size: input= {} | output= {}'.format(xi_valid.shape, yi_valid.shape))\n",
    "        \n",
    "    #train\n",
    "    _sigmoid_svm.fit(xi_train, yi_train)\n",
    "    \n",
    "    #valid\n",
    "    y_train_predicted = _sigmoid_svm.predict(xi_train) \n",
    "    y_valid_predicted = _sigmoid_svm.predict(xi_valid)\n",
    "    \n",
    "    #report\n",
    "    print ('\\t\\t report train:')\n",
    "    report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "    print ('\\t\\t report valid:')\n",
    "    acc = report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    report_file = 'models/svm/report_linear_svm_{}.txt'.format(iteration)\n",
    "    if os.path.exists(report_file):\n",
    "        os.remove(report_file)\n",
    "    with open(report_file, 'w') as f:\n",
    "         with redirect_stdout(f):\n",
    "                report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "                report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        sigmoid_svm = _sigmoid_svm\n",
    "        \n",
    "        with open('models/svm/sigmoid/best_svm_model.txt', 'w') as f:\n",
    "            f.write(str(iteration))\n",
    "    \n",
    "    with open('models/svm/sigmoid/svm_{}'.format(iteration), 'wb') as f:\n",
    "        f.write(pickle.dumps(_sigmoid_svm))\n",
    "          \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = sigmoid_svm.predict(X_test)\n",
    "\n",
    "print ('==> test Linear SVM')\n",
    "print ('\\t\\033[94m Report \\033[0m')\n",
    "_ = report(Y_test, y_test_predicted, prefix='\\t')\n",
    "print ('\\n')\n",
    "print ('\\t\\033[94m Normalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=True)\n",
    "print ('\\t\\033[94m Unnormalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poly SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "# nu     = 0.5\n",
    "# kernel = poly\n",
    "# degree = 4\n",
    "# gamma  = 1/(n_features*X.var())\n",
    "# coef0  = 0\n",
    "# probability = True\n",
    "# tol    = 1e-7\n",
    "# verbose     = 0\n",
    "# random_state= 42\n",
    "# max_iter    = 1e7\n",
    "# decision_function_shape = 'ovr'\n",
    "_poly_svm = NuSVC(kernel='poly', degree=4, gamma='scale', probability=True, tol=1e-7, max_iter=1e7, random_state=42)\n",
    "poly_svm  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, random_state=42, shuffle=True)\n",
    "\n",
    "print ('==> training Poly SVM:')\n",
    "iteration = 0\n",
    "best_acc  = 0\n",
    "for itrain, ivalid in kfold.split(X_train, Y_train):\n",
    "    print ('\\t\\033[94m iteration {}\\033[0m'.format(iteration))\n",
    "    \n",
    "    #split dataset into train and valid, based on folds\n",
    "    xi_train, xi_valid = X_train[itrain], X_train[ivalid]\n",
    "    yi_train, yi_valid = Y_train[itrain], Y_train[ivalid]\n",
    "    print ('\\t\\t train size: input= {} | output= {}'.format(xi_train.shape, yi_train.shape))\n",
    "    print ('\\t\\t valid size: input= {} | output= {}'.format(xi_valid.shape, yi_valid.shape))\n",
    "        \n",
    "    #train\n",
    "    _poly_svm.fit(xi_train, yi_train)\n",
    "    \n",
    "    #valid\n",
    "    y_train_predicted = _poly_svm.predict(xi_train) \n",
    "    y_valid_predicted = _poly_svm.predict(xi_valid)\n",
    "    \n",
    "    #report\n",
    "    print ('\\t\\t report train:')\n",
    "    report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "    print ('\\t\\t report valid:')\n",
    "    acc = report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    report_file = 'models/svm/report_linear_svm_{}.txt'.format(iteration)\n",
    "    if os.path.exists(report_file):\n",
    "        os.remove(report_file)\n",
    "    with open(report_file, 'w') as f:\n",
    "         with redirect_stdout(f):\n",
    "                report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "                report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        poly_svm = _poly_svm\n",
    "        \n",
    "        with open('models/svm/poly/best_svm_model.txt', 'w') as f:\n",
    "            f.write(str(iteration))\n",
    "    \n",
    "    with open('models/svm/poly/svm_{}'.format(iteration), 'wb') as f:\n",
    "        f.write(pickle.dumps(_poly_svm))\n",
    "          \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = poly_svm.predict(X_test)\n",
    "\n",
    "print ('==> test Poly SVM')\n",
    "print ('\\t\\033[94m Report \\033[0m')\n",
    "_ = report(Y_test, y_test_predicted, prefix='\\t')\n",
    "print ('\\n')\n",
    "print ('\\t\\033[94m Normalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=True)\n",
    "print ('\\t\\033[94m Unnormalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "# nu     = 0.5\n",
    "# kernel = rbf\n",
    "# gamma  = 1/(n_features*X.var())\n",
    "# probability = True\n",
    "# tol    = 1e-7\n",
    "# verbose     = 0\n",
    "# random_state= 42\n",
    "# max_iter    = 1e7\n",
    "# decision_function_shape = 'ovr'\n",
    "_rbf_svm = NuSVC(kernel='rbf', gamma='scale', probability=True, tol=1e-7, max_iter=1e7, random_state=42)\n",
    "rbf_svm  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, random_state=42, shuffle=True)\n",
    "\n",
    "print ('==> training Poly SVM:')\n",
    "iteration = 0\n",
    "best_acc  = 0\n",
    "for itrain, ivalid in kfold.split(X_train, Y_train):\n",
    "    print ('\\t\\033[94m iteration {}\\033[0m'.format(iteration))\n",
    "    \n",
    "    #split dataset into train and valid, based on folds\n",
    "    xi_train, xi_valid = X_train[itrain], X_train[ivalid]\n",
    "    yi_train, yi_valid = Y_train[itrain], Y_train[ivalid]\n",
    "    print ('\\t\\t train size: input= {} | output= {}'.format(xi_train.shape, yi_train.shape))\n",
    "    print ('\\t\\t valid size: input= {} | output= {}'.format(xi_valid.shape, yi_valid.shape))\n",
    "        \n",
    "    #train\n",
    "    _rbf_svm.fit(xi_train, yi_train)\n",
    "    \n",
    "    #valid\n",
    "    y_train_predicted = _rbf_svm.predict(xi_train) \n",
    "    y_valid_predicted = _rbf_svm.predict(xi_valid)\n",
    "    \n",
    "    #report\n",
    "    print ('\\t\\t report train:')\n",
    "    report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "    print ('\\t\\t report valid:')\n",
    "    acc = report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    report_file = 'models/svm/report_linear_svm_{}.txt'.format(iteration)\n",
    "    if os.path.exists(report_file):\n",
    "        os.remove(report_file)\n",
    "    with open(report_file, 'w') as f:\n",
    "         with redirect_stdout(f):\n",
    "                report(y_true=yi_train, y_pred=y_train_predicted, prefix='\\t\\t\\t')\n",
    "                report(y_true=yi_valid, y_pred=y_valid_predicted, prefix='\\t\\t\\t')\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        rbf_svm = _rbf_svm\n",
    "        \n",
    "        with open('models/svm/best_poly_svm_model.txt', 'w') as f:\n",
    "            f.write(str(iteration))\n",
    "    \n",
    "    with open('models/svm/poly_svm_{}'.format(iteration), 'wb') as f:\n",
    "        f.write(pickle.dumps(_rbf_svm))\n",
    "          \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = rbf_svm.predict(X_test)\n",
    "\n",
    "print ('==> test RBF SVM')\n",
    "print ('\\t\\033[94m Report \\033[0m')\n",
    "_ = report(Y_test, y_test_predicted, prefix='\\t')\n",
    "print ('\\n')\n",
    "print ('\\t\\033[94m Normalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=True)\n",
    "print ('\\t\\033[94m Unnormalized Confusion Matrix \\033[0m')\n",
    "make_confusion_matrix(y_true=Y_test, y_pred=y_test_predicted, names=['no', 'yes'], normalized=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
